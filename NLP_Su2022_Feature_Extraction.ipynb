{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Su2022 - Feature Extraction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pfenningpat/NLP22/blob/main/NLP_Su2022_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N-Grams**"
      ],
      "metadata": {
        "id": "h5nB3ei_OLpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk import *\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvUZUVfFO9PL",
        "outputId": "bca5d6e2-5fac-47c2-a42c-1d34ca66f97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InwH2oyUN6k_"
      },
      "outputs": [],
      "source": [
        "def n_gram_extractor(sentence, n):\n",
        "  tokens = re.sub(r'([^\\s\\w]|_)+', ' ', sentence).split()\n",
        "  for i in range(len(tokens)-n+1):\n",
        "    print(tokens[i:i+n])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_extractor('The cute little boy is playing with the kitten.', 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJrlB4ggOsWS",
        "outputId": "a598c714-ec27-406b-c6e1-ed5000fdaaa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'cute', 'little']\n",
            "['cute', 'little', 'boy']\n",
            "['little', 'boy', 'is']\n",
            "['boy', 'is', 'playing']\n",
            "['is', 'playing', 'with']\n",
            "['playing', 'with', 'the']\n",
            "['with', 'the', 'kitten']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk library\n",
        "from nltk import ngrams\n",
        "list(ngrams('The cute little boy is playing with the kitten.'.split(), 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqp3cWKqPNEZ",
        "outputId": "a6150e43-b123-470d-f400-adf0da4e3daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'cute'),\n",
              " ('cute', 'little'),\n",
              " ('little', 'boy'),\n",
              " ('boy', 'is'),\n",
              " ('is', 'playing'),\n",
              " ('playing', 'with'),\n",
              " ('with', 'the'),\n",
              " ('the', 'kitten.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using TextBlob\n",
        "from textblob import TextBlob\n",
        "blob = TextBlob(\"The cute little boy is playing with the kitten.\")\n",
        "blob.ngrams(n=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2i2wEm5PtOW",
        "outputId": "82d9b61a-e1ea-47b2-fb9c-2cadc92c3b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['The', 'cute']),\n",
              " WordList(['cute', 'little']),\n",
              " WordList(['little', 'boy']),\n",
              " WordList(['boy', 'is']),\n",
              " WordList(['is', 'playing']),\n",
              " WordList(['playing', 'with']),\n",
              " WordList(['with', 'the']),\n",
              " WordList(['the', 'kitten'])]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. And just as humans have a brain to process that input, computers have a program to process their respective inputs. At some point in processing, the input is converted to code that the computer can understand.'"
      ],
      "metadata": {
        "id": "2mMiK9KkSGAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "ePwENmQ1SU_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "0VaDjJw2SxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_word_sequence(sent)"
      ],
      "metadata": {
        "id": "8UnXpgAvTCxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0T1-u7CCUFoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob = TextBlob(sent)\n",
        "blob.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDLKqNdETNuH",
        "outputId": "83506408-3f8a-48be-f810-9cbcae285315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['NLP', 'enables', 'computers', 'to', 'understand', 'natural', 'language', 'as', 'humans', 'do', 'Whether', 'the', 'language', 'is', 'spoken', 'or', 'written', 'natural', 'language', 'processing', 'uses', 'artificial', 'intelligence', 'to', 'take', 'real-world', 'input', 'process', 'it', 'and', 'make', 'sense', 'of', 'it', 'in', 'a', 'way', 'a', 'computer', 'can', 'understand', 'Just', 'as', 'humans', 'have', 'different', 'sensors', 'such', 'as', 'ears', 'to', 'hear', 'and', 'eyes', 'to', 'see', 'computers', 'have', 'programs', 'to', 'read', 'and', 'microphones', 'to', 'collect', 'audio', 'And', 'just', 'as', 'humans', 'have', 'a', 'brain', 'to', 'process', 'that', 'input', 'computers', 'have', 'a', 'program', 'to', 'process', 'their', 'respective', 'inputs', 'At', 'some', 'point', 'in', 'processing', 'the', 'input', 'is', 'converted', 'to', 'code', 'that', 'the', 'computer', 'can', 'understand'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = TweetTokenizer()\n",
        "t.tokenize(sent)"
      ],
      "metadata": {
        "id": "sPu8yeSsTezL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Sunil tweeted, \"Witnessing 70th Republic Day of India from Rajpath, \\\n",
        "New Delhi. Mesmerizing performance by Indian Army! Awesome airshow! @india_official \\\n",
        "@indian_army #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :)\"'\n"
      ],
      "metadata": {
        "id": "sSP8Pa0KUHNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import MWETokenizer"
      ],
      "metadata": {
        "id": "4G5kcZLVTukB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mwe_tokenizer = MWETokenizer([('Republic', 'Day')])\n",
        "mwe_tokenizer.add_mwe(('Indian', 'Army'))\n",
        "#mwe_tokenizer.tokenize(sentence.split())\n",
        "mwe_tokenizer.tokenize(sentence.replace('!','').split())"
      ],
      "metadata": {
        "id": "P-9fe3NtT5nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "gqiDp-hlWoZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "re_stemmer = RegexpStemmer('ing$', 4)\n",
        "' '.join([re_stemmer.stem(wd) for wd in sentence.split()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oDv7C07XVWI3",
        "outputId": "8fd7f9af-6612-49a8-d359-c2d18de91719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sunil tweeted, \"Witness 70th Republic Day of India from Rajpath, New Delhi. Mesmeriz performance by Indian Army Awesome airshow! @india_official @indian_army #India #70thRepublic_Day. For more photos p me sunil@photoking.com :)\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Porter Stemmer\n",
        "from nltk.stem.porter import *"
      ],
      "metadata": {
        "id": "neaeKyZzYr__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps_stemmer = PorterStemmer()\n",
        "' '.join([ps_stemmer.stem(wd) for wd in sentence.split()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kSjZ0ghoY1AY",
        "outputId": "45b543f4-a0ac-4c96-adf1-b06aa9a8bebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunil tweeted, \"wit 70th republ day of india from rajpath, new delhi. mesmer perform by indian armi awesom airshow! @india_offici @indian_armi #india #70threpublic_day. for more photo ping me sunil@photoking.com :)\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "5yiGiot_ZMHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiAotFYEZJNP",
        "outputId": "4e9fb8bd-31a9-4bf7-c8be-245969caef10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(sentence)])"
      ],
      "metadata": {
        "id": "xRHL8rY6ZasY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}